Executive Summary :We have 4 CoLab-ready Jupyter Notebooks in GitHub to process NASA STELLA, Landsat and PACE Ocean data. Just click on the hyperlinks below for each notebook example. STS EXAMPLE 1: STELLA DATA SIMPLE APPLICATION:      CoLab_STELLA_brief_ver2_backyard_grass_shoreline_condensed.ipynbSTS EXAMPLE 2: PROCESS NASA LANDSAT DATA:      CoLab_VegIndex4_training_RobinsonPreserve_simple_Level2.ipynbSTS EXAMPLE 3: PROCESS NASA PACE HYPERSPECTRAL OCEAN DATA:This takes a while to load all HyperCoast[extra] python libraries and PACE dataset.  It takes ~5 minutes to run entire project to our ‘break’ point that stops the code. Beyond the break point are experimental Red Tide (Karenia brevis) indicators that have not been tested.       CoLab_ netCDF4_PACE.ipynbSTS COMPREHENSIVE EXAMPLE 4:  PROCESS AND PEDICT VEGETATIVE SPECIES FROM HOME DEPOT STELLA DATA:This too takes a while to load python libraries and data. It takes ~2 minutes to run. Check out the interactive Altair displays at the end where you can select samples from the plot to view the plant species photos for each reading.       CoLab_STELLA_brief_ver2_brief_to_Ed_Chiles_ver2.ipynbEARTH EXPLORER: If you need to setup an Earth Explorer account to download PACE or Landsat data, then please click on the following link:      Earth Explorer login.GOOGLE ACCOUNT: You will need to log into your Google Account to login. If you do not have one, then go to this link below:       Google AccountWe have not tested this link and are not aware of any costs for the basic account.HOW TO RUN IN COLAB:1) If you click on the Jupyter Notebook links that we have provided, you will see the following type of image while you are still in GitHub. Click on the banner "Open in CoLab” at the top, and this will open this notebook in Google CoLab. Look to the far upper right corner of the web page to make sure that you are logged into your google account. If not, then login before trying to run CoLab. 2) On the top title bar of CoLab there is a label called “Runtime” (second image below). Click on this and then click on “Run all”. That is it. The notebook will get all of the data files and run python. It could take a few minutes, but I have tested this in my environment, and it works fine. 3) When finished, then I would suggest in the “Runtime” column, click on “Disconnect and delete runtime” to end your CoLab session. 
Example by Example Discussion:1)  STS STELLA DATA EXAMPLE 1:We are looking for a backup plan just in case we cannot run our STS python software on FabLab PCs. Google CoLab is probably our Plan B. All that is required is a Google Account login. All students will need this too as well as an Earth Explorer login.For this application, you can go to the GitHub site, or click on the link below. This is the hyperlink to the Jupyter Notebook in this repository:      CoLab_STELLA_brief_ver2_backyard_grass_shoreline_condensed.ipynbIf you click on this Jupyter Notebook you will see the following image while in GitHub. Click on the banner "Open in CoLab” at the top, and this will open this notebook in CoLab. Look to the far upper right to make sure that you are logged into your google account. If not, then login. On the top title bar of CoLab there is a label called “Runtime” (second image below). Click on this and then click on “Run all”. That is it. The notebook will get all of the data files and run python. It could take a few minutes, but I have tested this in my environment, and it works fine. When finished, then I would suggest in the “Runtime” column, click on “Disconnect and delete runtime”. This basic code will perform the following steps:- Load the STELLA data and White-Card correction data- display all Raw spectral wavelengths for each reading with the “Test" label for various Test patterns in this dataset (Asphalt, Grass, shady grass, White-Card, and shady grass and shady White-Card and finally the shoreline deposits of the lake). - Apply White-Card normalization factors to each wavelength for each reading- Display the White-Card Corrected spectral data for each reading- Calculate and display NDVI for all readingsThis is our first CoLab Plan B example for the course. This can also be run by all participants from home too. In addition, there are a number of repositories on our STS GitHub that have CoLab friendly notebooks on everything from more STELLA examples, Landsat processing for NDVI and even the new Ocean data from the PACE satellite data where we calculate Chlorophyll a over the entire Gulf Coast region. 2)  STS COLAB EXAMPLE 2 USING LANDSAT DATA:Again, looking for a backup using Google CoLab, we now have an example for Landsat Processing. All that is required is a Google Account login. All students will need this too just in case as well as an Earth Explorer login. Anyway, for this test, you can go to the GitHub site, or click on the link below. This is the hyperlink to the Jupyter Notebook in this repository:      CoLab_VegIndex4_training_RobinsonPreserve_simple_Level2.ipynbIf you click on this Jupyter Notebook you will see the following image while in GitHub. Click on the banner "Open in CoLab” at the top, and this will open this notebook in CoLab. Look to the far upper right to make sure that you are logged into your google account. If not, then login. On the top title bar of CoLab there is a label called “Runtime” (second image below). Click on this and then click on “Run all”. That is it. The notebook will get all of the data files and run python. It could take a few minutes, but I have tested this in my environment, and it works fine. When finished, then I would suggest in the “Runtime” column, click on “Disconnect and delete runtime”. This basic code will perform the following steps:- Download all necessary data- Correct Landsat Bands 4 (Red) and 5 (NIR) from integer to decimal numbers- Display Landsat Band data- Calculate NDVI- Display NDVI from Landsat as a histogram and image- Load geojson mapped Mangrove Habitat locations- Determine NDVI cutoff values falling under the mapped Mangrove Habitats from NDVI histogram- Remap Landsat derived NDVI using histogram normalization to create the colors for NDVI This is our 2nd CoLab Plan B example for the course. This can also be run by all participants from home too. Examples Below are considered Additional Resources, but not within the scope of this class.3)  STS COLAB EXAMPLE 3 USING PACE OCEAN DATA:Again, looking for a backup using Google CoLab, we now have an example for NASA Ocean Pace Hyperspectral Processing. All that is required is a Google Account login. All students will need this too just in case as well as an Earth Explorer login. Anyway, for this test, you can go to the GitHub site, or click on the link below.This is the hyperlink to the Jupyter Notebook in this repository:      CoLab_ netCDF4_PACE.ipynbIf you click on this Jupyter Notebook you will see the following image while in GitHub. Click on the banner "Open in CoLab” at the top, and this will open this notebook in CoLab. Look to the far upper right to make sure that you are logged into your google account. If not, then login. On the top title bar of CoLab there is a label called “Runtime” (second image below). Click on this and then click on “Run all”. That is it. The notebook will get all of the data files and run python. It could take 5 minutes, but I have tested this in my environment, and it works fine. When finished, then I would suggest in the “Runtime” column, click on “Disconnect and delete runtime”. This basic code will perform the following steps:- Download all necessary data- Explore Hyperspectral data. Each satellite pixel has 184 channels of spectral data- Plot PACE data on map- Calculate Chlorophyll a- Display Chlorophyll a- We have a break in our notebook that stops after the Chlorophyll a is displayed, but numerous potential  Red Tide indicators are calculated. A lot of work needs to be done here. This is our 3rd CoLab Plan B example, but beyond the scope of this course. However, this program can be run by all participants from home too.4)  LAST STS COLAB EXAMPLE 4 USES NICK’s HOME DEPOT VEGETATIVE DATA TO BUILD MODELS TO PREDICT PLANT SPECIES:This is the last STS CoLab example and is beyond the scope of this class, but it is available for others to view to view how we actually characterize STELLA  data by Plant species and then use Scikit learn to predict these plant types using supervised learning. This example calculates the mean of each plant species and then these End Members are used in supervised learning to predict plant species from other STELLA spectral data with similar plant species too. This is the GitHub link or go to the link below. This is the hyperlink to the Jupyter Notebook in this repository:      CoLab_STELLA_brief_ver2_brief_to_Ed_Chiles_ver2.ipynbIf you click on this Jupyter Notebook you will see the following image while in GitHub. Click on the banner "Open in CoLab” at the top, and this will open this notebook in CoLab. Look to the far upper right to make sure that you are logged into your google account. If not, then login. On the top title bar of CoLab there is a label called “Runtime” (second image below). Click on this and then click on “Run all”. That is it. The notebook will get all of the data files and run python. It could take a few minutes, but I have tested this in my environment, and it works fine. When finished, then I would suggest in the “Runtime” column, click on “Disconnect and delete runtime”. This basic code will perform the following steps:- Load the STELLA data and White-Card correction data- display all Raw spectral wavelengths for each reading with the “Test" label for various Test patterns in this dataset- Apply White-Card normalization factors to each wavelength for each reading- Display the White-Card Corrected spectral data for each reading	- almost all wavelength plot methods used- Calculate and display NDVI for all readings- Perform 3D cross plots of key spectral data and calculate end members of each plant type to represent our supervised clusters centers- Run Decision Tree to better understand the logic used to differentiate one plant from the next.- Use Knn to differentiate pant types in a very transparent manner. - Use python’s powerful Altar package to view representative photos fore each reading using Cross plots and NDVI time-series plots to show images of the plant types to help us better understand the STELLA results (see below)This is our 4th CoLab Plan B example, but beyond the scope of this course. However, this program can be run by all participants from home too. 